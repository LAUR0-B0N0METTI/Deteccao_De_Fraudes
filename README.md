## Sistema de DetecÃ§Ã£o de Fraudes em Tempo Real  
**Autor:** Lauro Bonometti  
**E-mail:** lauro.f.bonometti@gmail.com  
**LinkedIn:** [linkedin.com/in/laurobonometti](https://www.linkedin.com/in/laurobonometti)  

---

## ðŸ“‹ SumÃ¡rio  
1. [VisÃ£o Geral](#visÃ£o-geral)  
2. [Tecnologias Utilizadas](#tecnologias-utilizadas)  
3. [Arquitetura e Fluxo de Dados](#arquitetura-e-fluxo-de-dados)  
4. [DescriÃ§Ã£o dos Blocos de CÃ³digo](#descriÃ§Ã£o-dos-blocos-de-cÃ³digo)  
5. [MÃ©tricas e Resultados Indicativos](#mÃ©tricas-e-resultados-indicativos)  
6. [Como Executar](#como-executar)  
7. [PrÃ³ximos Passos](#prÃ³ximos-passos)  

---

## ðŸ” VisÃ£o Geral  
Este projeto implementa um pipeline de detecÃ§Ã£o de fraudes em transaÃ§Ãµes financeiras, que combina dois mÃ©todos de detecÃ§Ã£o de anomalias:  
- **Isolation Forest**  
- **Autoencoder (Deep Learning)**  

Ao final, gera-se um **ensemble** que decide â€œfraudeâ€ com base na mÃ©dia das pontuaÃ§Ãµes normalizadas de cada modelo, usando um threshold calibrado via anÃ¡lise de custo (FP vs. FN).

---

## ðŸ›  Tecnologias Utilizadas  
- **Python 3.8+**: linguagem principal  
- **Pandas / NumPy**: manipulaÃ§Ã£o de dados  
- **scikit-learn**: IsolationForest, mÃ©tricas, train_test_split  
- **TensorFlowâ€‰/â€‰Keras**: construÃ§Ã£o e treino do autoencoder  
- **Matplotlib**: visualizaÃ§Ã£o de curvas ROC/PR  
- **Joblib**: persistÃªncia de modelos  
- **Google Colab**: ambiente de desenvolvimento e experimentaÃ§Ã£o  
- **Gitâ€‰/â€‰GitHub**: versionamento e apresentaÃ§Ã£o do cÃ³digo  

---

## ðŸ— Arquitetura e Fluxo de Dados  
1. **Leitura em chunks**  
   - TransaÃ§Ãµes (`train_transaction.csv`) e identidades (`train_identity.csv`) sÃ£o lidas em pedaÃ§os para economizar memÃ³ria.  
   - Junta-se apenas as identidades cujos IDs aparecem nas transaÃ§Ãµes carregadas.  
2. **AnÃ¡lise exploratÃ³ria**  
   - Amostragem de atÃ© 10 000 registros para inspeÃ§Ã£o de distribuiÃ§Ã£o de fraudes, tipos de dados e valores nulos.  
3. **ReduÃ§Ã£o de dimensionalidade**  
   - Remove colunas com >70 % de valores nulos.  
   - Descarta variÃ¡veis de variÃ¢ncia quase zero.  
   - MantÃ©m apenas as top 100 variÃ¡veis mais correlacionadas com o rÃ³tulo `isFraud`.  
4. **PrÃ©-processamento**  
   - Separa features e alvo.  
   - Factoriza categÃ³ricas, imputaÃ§Ã£o de missing (mediana).  
   - Normaliza via `StandardScaler`.  
   - Gera treino/teste (80 / 20 %).  
5. **Treinamento dos Modelos**  
   - **Isolation Forest**  
     - Usa 100 Ã¡rvores, contaminaÃ§Ã£o = proporÃ§Ã£o de fraudes no treino.  
     - Gera score de anomalia, normaliza entre 0â€“1.  
   - **Autoencoder**  
     - Rede densa com codificaÃ§Ã£o de dimensÃ£o â‰ˆ 1/3 das features (mÃ¡x 64), decoder simÃ©trico.  
     - EarlyStopping (patience=5), salva melhor modelo no formato nativo Keras.  
     - Calcula MSE de reconstruÃ§Ã£o em batches e normaliza.  
6. **AvaliaÃ§Ã£o e CalibraÃ§Ã£o**  
   - Para cada modelo, encontra threshold que maximiza F1 na curva Precisionâ€“Recall.  
   - Ensemble threshold = mÃ©dia dos thresholds individuais.  
   - **SimulaÃ§Ã£o de custo**: varia threshold em [0,1], conta FP Ã— custo_FP + FN Ã— custo_FN, escolhe threshold mÃ­nimo.  
   - Com custo_FP=10  e custo_FN=100, threshold final = 0.33.  
7. **Detector em Tempo Real**  
   - FunÃ§Ã£o que recebe uma transaÃ§Ã£o (pandas.DataFrame 1Ã—N), aplica mesmÃ­ssimo prÃ©-processamento e retorna:  
     ```json
     {
       "fraude": true|false,
       "scores": {"iso":0.x, "ae":0.y, "ens":0.z}
     }
     ```

---

## ðŸ“‘ DescriÃ§Ã£o dos Blocos de CÃ³digo  

| Bloco | FunÃ§Ã£o Principal | ComentÃ¡rios |
|---|---|---|
| **1. Imports & ConfiguraÃ§Ã£o** | carrega bibliotecas, define `logging`, `limpar_memoria()` | Import Ãºnico de pacotes, warnings off. |
| **2. `carregar_dados_em_chunks()`** | lÃª CSVs em pedaÃ§os, concatena, amostra atÃ© 50 000 registros | Minimiza uso de RAM; trata falha de identity como opcional. |
| **3. `analisar_dados()`** | imprime shape, distribuiÃ§Ã£o de fraudes, nulos e tipos | Ajuda a garantir qualidade antes de modelar. |
| **4. `reduzir_dimensoes()`** | descarta colunas >70 % nulas e baixa variÃ¢ncia; retÃ©m top N corr. | Reduz de dezenas a poucas centenas de features. |
| **5. `preprocessar_dados()`** | factoriza categÃ³ricas, fillna, split treino/teste, normaliza | Gera arrays prontos para sklearn/TensorFlow. |
| **6. `treinar_isolation_forest()`** | treina modelo, normaliza scores de anomalia | Usa atÃ© 50 000 amostras do treino para economizar tempo. |
| **7. `treinar_autoencoder()`** | constrÃ³i e treina rede, salva melhor, calcula MSE normalizado | EarlyStopping, ModelCheckpoint (.keras), batches de inferÃªncia. |
| **8. `avaliar_modelos()`** | encontra thresholds via PR-curve; plota ROC; retorna thresholds | Thresholds iso, ae, ensemble. |
| **9. CalibraÃ§Ã£o de Custo** | `calibrar_por_custo()` varre thresholds contando FP/FN, minimiza custo | Pareto entre alerta falso e fraude nÃ£o capturada. |
| **10. `implementar_sistema_tempo_real()`** | retorna funÃ§Ã£o `detectar(transacao)` | Pronta para deploy; aceita DataFrame simples. |
| **11. `executar_sistema()`** | orquestra todo o pipeline, retorna `detector` e `X_test` | Ponto de entrada do script / notebook. |
| **12. Teste de Batch & Export** | aplica `detector()` em N exemplos; grava CSV | Facilita auditoria e revisÃ£o manual de alertas. |

---

## ðŸ“Š MÃ©tricas e Resultados Indicativos  
- **Isolated Forest**  
  - AUC-ROC: ~0.83  
  - F1 Ã³timo: 0.18 @ threshold 0.59  
- **Autoencoder**  
  - AUC-ROC: ~0.86  
  - F1 Ã³timo: 0.20 @ threshold 0.06  
- **Ensemble**  
  - AUC-ROC: ~0.88  
  - F1 Ã³timo: 0.19 @ threshold 0.33  
- **CalibraÃ§Ã£o de Custo (custo_FP=10, custo_FN=100)**  
  - **Threshold final:** 0.33  
  - **FP:** 153 alertas falsos  
  - **FN:** 227 fraudes perdidas  
  - **Custo estimado:** R\$ 24 230  

---

## â–¶ Como Executar  
1. **Clone o repositÃ³rio**  
   ```bash
   git clone https://github.com/seu-usuario/bank-churn-analytics-pro.git
   cd bank-churn-analytics-pro
   ```  
2. **Abra no Colab**  
   - Carregue o notebook `detector_fraudes.ipynb`.  
   - Garanta que o diretÃ³rio `sample_data/dados` contÃ©m os CSVs.  
3. **Execute as cÃ©lulas na ordem**  
   - Imports â†’ FunÃ§Ãµes â†’ Pipeline â†’ CalibraÃ§Ã£o â†’ Testes â†’ ExportaÃ§Ã£o.  
4. **Ajuste parÃ¢metros**  
   - `max_rows`, `max_features`, `custo_fp`, `custo_fn`, `threshold_piso` conforme necessidade.  

---

## ðŸ“ˆ PrÃ³ximos Passos  
- Criar dashboard em Streamlit para enviar transaÃ§Ã£o em tempo real.  
- Adicionar testes unitÃ¡rios (prÃ©-processamento, formatos de entrada) e integraÃ§Ã£o contÃ­nua.  
- Configurar monitoramento de drift de dados em produÃ§Ã£o.  
- Incorporar feedback humano (fraudes confirmadas) para re-treinos periÃ³dicos.  

---

> **Contato**: Lauro Bonometti â€¢ lauro.f.bonometti@gmail.com â€¢ [linkedin.com/in/laurobonometti](https://www.linkedin.com/in/laurobonometti)